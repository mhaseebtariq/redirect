{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e28771f1e4c3a84",
   "metadata": {},
   "source": [
    "## Please download the following dataset:\n",
    "* https://www.kaggle.com/datasets/ealtman2019/ibm-transactions-for-anti-money-laundering-aml\n",
    "## And extract the files to ./synthetic-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb5afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import types as st\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "import settings as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40b21f-0f55-40dc-93eb-e449cd1cf5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    sys.version_info.major,\n",
    "    sys.version_info.minor,\n",
    "    sys.version_info.micro,\n",
    ") != (3, 9, 19):\n",
    "    raise EnvironmentError(\n",
    "        \"Only runs efficiently on Python 3.9.19 (Tested on: Conda 24.1.2 | Apple M3 Pro)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    (\"spark.driver.memory\", \"8g\"),\n",
    "    (\"spark.worker.memory\", \"8g\"),\n",
    "]\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"testing\")\n",
    "    .config(conf=SparkConf().setAll(config))\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(value):\n",
    "    return f\"id-{hash(value)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa090168",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.remove(s.STAGED_DATA_CSV_LOCATION)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "\n",
    "mapping = {}\n",
    "with open(s.DATA_FILE) as in_file:\n",
    "    cnt = -1\n",
    "    lines = \"\"\n",
    "    for line in in_file:\n",
    "        cnt += 1\n",
    "        if cnt == 0:\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        line_id = get_id(line)\n",
    "        mapping[line_id] = cnt\n",
    "        lines += f\"{cnt},{line}\\n\"\n",
    "        if not (cnt % 2e7):\n",
    "            print(cnt)\n",
    "            with open(s.STAGED_DATA_CSV_LOCATION, \"a\") as out_file:\n",
    "                out_file.write(lines)\n",
    "                lines = \"\"\n",
    "if lines:\n",
    "    lines = lines.strip()\n",
    "    with open(s.STAGED_DATA_CSV_LOCATION, \"a\") as out_file:\n",
    "        out_file.write(lines)\n",
    "        del lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467df787",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove(s.STAGED_PATTERNS_CSV_LOCATION)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "lines = \"\"\n",
    "with open(s.PATTERNS_FILE) as in_file:\n",
    "    for line in in_file:\n",
    "        line = line.strip()\n",
    "        if line[:4].isnumeric():\n",
    "            line_id = get_id(line)\n",
    "            cnt = mapping[line_id]\n",
    "            lines += f\"{cnt},{line}\\n\"\n",
    "        else:\n",
    "            lines += f\"{line}\\n\"\n",
    "\n",
    "lines = lines.strip()\n",
    "with open(s.STAGED_PATTERNS_CSV_LOCATION, \"a\") as out_file:\n",
    "    out_file.write(lines)\n",
    "    del lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304986b5-67dd-431d-b77a-8987b4fcd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = st.StructType(\n",
    "    [\n",
    "        st.StructField(\"transaction_id\", st.IntegerType(), False),\n",
    "        st.StructField(\"timestamp\", st.TimestampType(), False),\n",
    "        st.StructField(\"source_bank\", st.StringType(), False),\n",
    "        st.StructField(\"source\", st.StringType(), False),\n",
    "        st.StructField(\"target_bank\", st.StringType(), False),\n",
    "        st.StructField(\"target\", st.StringType(), False),\n",
    "        st.StructField(\"received_amount\", st.FloatType(), False),\n",
    "        st.StructField(\"receiving_currency\", st.StringType(), False),\n",
    "        st.StructField(\"sent_amount\", st.FloatType(), False),\n",
    "        st.StructField(\"sending_currency\", st.StringType(), False),\n",
    "        st.StructField(\"format\", st.StringType(), False),\n",
    "        st.StructField(\"is_laundering\", st.IntegerType(), False),\n",
    "    ]\n",
    ")\n",
    "columns = [x.name for x in schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ee4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(s.STAGED_PATTERNS_CSV_LOCATION, \"r\") as fl:\n",
    "    patterns = fl.read()\n",
    "\n",
    "cases = []\n",
    "case_id = 0\n",
    "for pattern in patterns.split(\"\\n\\n\"):\n",
    "    case_id += 1\n",
    "    if not pattern.strip():\n",
    "        continue\n",
    "    pattern = pattern.split(\"\\n\")\n",
    "    name = pattern.pop(0).split(\" - \")[1]\n",
    "    category, sub_category = name, name\n",
    "    if \": \" in name:\n",
    "        category, sub_category = name.split(\": \")\n",
    "    pattern.pop()\n",
    "    case = pd.DataFrame([x.split(\",\") for x in pattern], columns=columns)\n",
    "    case.loc[:, \"id\"] = case_id\n",
    "    case.loc[:, \"type\"] = category.strip().lower()\n",
    "    case.loc[:, \"sub_type\"] = sub_category.strip().lower()\n",
    "    cases.append(case)\n",
    "cases = pd.concat(cases, ignore_index=True)\n",
    "cases = spark.createDataFrame(cases)\n",
    "cases = cases.withColumn(\"timestamp\", sf.to_timestamp(\"timestamp\", s.TIMESTAMP_FORMAT))\n",
    "cases = cases.select(\"transaction_id\", \"id\", \"type\", \"sub_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45180d75-a337-468b-89e3-38f1b82646f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_MAPPING = {\n",
    "    \"Australian Dollar\": \"aud\",\n",
    "    \"Bitcoin\": \"btc\",\n",
    "    \"Brazil Real\": \"brl\",\n",
    "    \"Canadian Dollar\": \"cad\",\n",
    "    \"Euro\": \"eur\",\n",
    "    \"Mexican Peso\": \"mxn\",\n",
    "    \"Ruble\": \"rub\",\n",
    "    \"Rupee\": \"inr\",\n",
    "    \"Saudi Riyal\": \"sar\",\n",
    "    \"Shekel\": \"ils\",\n",
    "    \"Swiss Franc\": \"chf\",\n",
    "    \"UK Pound\": \"gbp\",\n",
    "    \"US Dollar\": \"usd\",\n",
    "    \"Yen\": \"jpy\",\n",
    "    \"Yuan\": \"cny\",\n",
    "}\n",
    "\n",
    "currency_code = sf.udf(lambda x: CURRENCY_MAPPING[x], st.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb394c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = spark.read.csv(\n",
    "    s.STAGED_DATA_CSV_LOCATION,\n",
    "    header=False,\n",
    "    schema=schema,\n",
    "    timestampFormat=s.TIMESTAMP_FORMAT,\n",
    ")\n",
    "group_by = [\n",
    "    \"timestamp\",\n",
    "    \"source_bank\",\n",
    "    \"source\",\n",
    "    \"target_bank\",\n",
    "    \"target\",\n",
    "    \"receiving_currency\",\n",
    "    \"sending_currency\",\n",
    "    \"format\",\n",
    "]\n",
    "data = data.groupby(group_by).agg(\n",
    "    sf.first(\"transaction_id\").alias(\"transaction_id\"),\n",
    "    sf.collect_set(\"transaction_id\").alias(\"transaction_ids\"),\n",
    "    sf.sum(\"received_amount\").alias(\"received_amount\"),\n",
    "    sf.sum(\"sent_amount\").alias(\"sent_amount\"),\n",
    "    sf.max(\"is_laundering\").alias(\"is_laundering\"),\n",
    ")\n",
    "data = data.withColumn(\n",
    "    \"source_currency\", currency_code(sf.col(\"sending_currency\"))\n",
    ").withColumn(\n",
    "    \"target_currency\",\n",
    "    currency_code(sf.col(\"receiving_currency\")),\n",
    ")\n",
    "data = data.join(cases, on=\"transaction_id\", how=\"left\").repartition(\n",
    "    128, \"transaction_id\"\n",
    ")\n",
    "data = data.select(\n",
    "    \"transaction_id\",\n",
    "    \"transaction_ids\",\n",
    "    \"timestamp\",\n",
    "    sf.concat(sf.col(\"source\"), sf.lit(\"-\"), sf.col(\"source_currency\")).alias(\"source\"),\n",
    "    sf.concat(sf.col(\"target\"), sf.lit(\"-\"), sf.col(\"target_currency\")).alias(\"target\"),\n",
    "    \"source_bank\",\n",
    "    \"target_bank\",\n",
    "    \"source_currency\",\n",
    "    \"target_currency\",\n",
    "    sf.col(\"sent_amount\").alias(\"source_amount\"),\n",
    "    sf.col(\"received_amount\").alias(\"target_amount\"),\n",
    "    \"format\",\n",
    "    \"is_laundering\",\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4b7c6-8740-48ac-9314-25ebf3e56862",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select(sf.explode(\"transaction_ids\")).count() - data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0364dec-3ed8-4213-b7a8-4f6f9eba67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_data = (\n",
    "    cases.join(\n",
    "        data.withColumnRenamed(\"transaction_id\", \"x\")\n",
    "        .drop(*cases.columns)\n",
    "        .select(sf.explode(\"transaction_ids\").alias(\"transaction_id\"), \"*\"),\n",
    "        on=\"transaction_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .drop(\"is_laundering\", \"transaction_id\", \"transaction_ids\")\n",
    "    .withColumnRenamed(\"x\", \"transaction_id\")\n",
    ")\n",
    "cases_data.toPandas().to_parquet(s.STAGED_CASES_DATA_LOCATION)\n",
    "cases_data = pd.read_parquet(s.STAGED_CASES_DATA_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5cfc5-cc6f-45b0-b717-bb73c52e9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"transaction_ids\")\n",
    "data.write.parquet(s.STAGED_DATA_LOCATION, mode=\"overwrite\")\n",
    "data = spark.read.parquet(s.STAGED_DATA_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15609486-de3c-4470-928e-612aa35a08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.count() == data.select(\"transaction_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count(), cases_data.shape[0], cases_data[\"transaction_id\"].nunique(), cases_data[\n",
    "    \"id\"\n",
    "].nunique()\n",
    "# (179504480, 137936, 137933, 16467)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
