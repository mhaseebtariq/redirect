{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd66cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import shutil\n",
    "import sys\n",
    "import uuid\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import timedelta, date\n",
    "from glob import glob\n",
    "\n",
    "import leidenalg as la\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from pyspark.sql import functions as sf, types as st\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "import settings as s\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78718f0-7f15-4c1f-963f-bd160efec0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    sys.version_info.major, \n",
    "    sys.version_info.minor, \n",
    "    sys.version_info.micro,\n",
    ") != (3, 11, 8):\n",
    "    raise EnvironmentError(\"Only runs efficiently on Python 3.11.7 | conda 24.1.2 | Apple M3 Pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    (\"spark.driver.memory\", \"8g\"),\n",
    "    (\"spark.worker.memory\", \"8g\"),\n",
    "]\n",
    "spark = SparkSession.builder.appName(\"testing\").config(conf=SparkConf().setAll(config)).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc52ce-1f9d-49d2-81f7-366fcdab6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_script = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2442c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.parquet(s.STAGED_DATA_LOCATION)\n",
    "data = data.where(sf.col(\"source\") != sf.col(\"target\"))\n",
    "data = data.where(sf.col(\"format\").isin([\"ACH\", \"Wire\", \"Bitcoin\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f687f-1bdd-4995-9fc7-cd17e58c7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_edges(data_input):\n",
    "    data_aggregated = data_input.groupby([\"source\", \"target\"]).agg(\n",
    "        sf.sum(\"source_amount\").alias(\"source_amount\"),\n",
    "        sf.sum(\"target_amount\").alias(\"target_amount\"),\n",
    "    ).toPandas()\n",
    "    \n",
    "    source_totals = data_aggregated.groupby(\n",
    "        \"source\"\n",
    "    ).agg({\"source_amount\": \"sum\"})[\"source_amount\"].to_dict()\n",
    "    target_totals = data_aggregated.groupby(\n",
    "        \"target\"\n",
    "    ).agg({\"target_amount\": \"sum\"})[\"target_amount\"].to_dict()\n",
    "    \n",
    "    data_aggregated.loc[:, \"total_sent_by_source\"] = data_aggregated.loc[:, \"source\"].apply(\n",
    "        lambda x: source_totals[x]\n",
    "    )\n",
    "    data_aggregated.loc[:, \"total_received_by_target\"] = data_aggregated.loc[:, \"target\"].apply(\n",
    "        lambda x: target_totals[x]\n",
    "    )\n",
    "    data_aggregated.loc[:, \"weight\"] = data_aggregated.apply(\n",
    "        lambda x: (\n",
    "            (x[\"source_amount\"] / x[\"total_sent_by_source\"]) +\n",
    "            (x[\"target_amount\"] / x[\"total_received_by_target\"])\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    data_aggregated.loc[:, \"source\"] = data_aggregated[\"source\"].str.slice(0, 8)\n",
    "    data_aggregated.loc[:, \"target\"] = data_aggregated[\"target\"].str.slice(0, 8)\n",
    "    filter_self = data_aggregated[\"source\"] != data_aggregated[\"target\"]\n",
    "    data_aggregated = data_aggregated.loc[filter_self, :].reset_index(drop=True)\n",
    "    return data_aggregated.loc[:, [\"source\", \"target\", \"weight\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb53cf-ffc6-42ad-bc74-87b5f8cc2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "edges = aggregate_edges(data)\n",
    "graph = ig.Graph.DataFrame(edges, use_vids=False, directed=True)\n",
    "nodes = [x[\"name\"] for x in graph.vs()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba166fa-7b4f-4e05-b3cd-8aac40f5a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processes(ids):\n",
    "    processes = []\n",
    "    for process in psutil.process_iter():\n",
    "        cmdline = []\n",
    "        try:\n",
    "            cmdline = process.cmdline()\n",
    "        except Exception as error:\n",
    "            pass\n",
    "        if ids.intersection(cmdline):\n",
    "            processes.append(process)\n",
    "    return processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20b900-1cff-4b99-83cf-9072ed4ac5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "NUMBER_OF_PROCESSES = 10\n",
    "\n",
    "shutil.rmtree(\"staging\", ignore_errors=True)\n",
    "os.mkdir(\"staging\")\n",
    "chunks = np.array_split(nodes, NUMBER_OF_PROCESSES)\n",
    "\n",
    "filename = \"graph.pickle\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(graph, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "filename = \"nodes.pickle\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(chunks, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "process_ids = set()\n",
    "process_name = \"communities.py\"\n",
    "for chunk_number in range(NUMBER_OF_PROCESSES):\n",
    "    process_id = str(uuid.uuid4())\n",
    "    process_ids = process_ids.union({process_id})\n",
    "    os.system(f\"{sys.executable} {process_name} {chunk_number} {process_id} &\")\n",
    "\n",
    "while get_processes(process_ids):\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0293b2-a6f7-4d28-b1df-8b4ee157d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for proc in get_processes(process_ids):\n",
    "    try:\n",
    "        proc.kill()\n",
    "    except psutil.NoSuchProcess:\n",
    "        pass\n",
    "\n",
    "communities = []\n",
    "for filename in glob(\"./staging/*.pickle\"):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        communities += pickle.load(f)\n",
    "\n",
    "filename = \"communities.pickle\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(communities, f)\n",
    "communities = [x[1] for x in communities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a3aa9-cf42-44dd-acff-30ba54f852fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec60f2-a77e-440b-bd4a-6358899831be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "location = \"cyclic_transactions.parquet\"\n",
    "columns = [\"source\", \"target\"]\n",
    "cyclic_transactions = pd.read_parquet(location).drop_duplicates(subset=columns)\n",
    "cyclic_transactions = cyclic_transactions.loc[:, columns].set_index(columns)\n",
    "edges_cyclic = cyclic_transactions.join(edges.set_index(columns)).reset_index()\n",
    "graph_cyclic = ig.Graph.DataFrame(edges_cyclic, use_vids=False, directed=True)\n",
    "nodes_filtered = [x[\"name\"] for x in graph_cyclic.vs()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be91e4ae-2dd3-4687-9c73-16529665a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "NUMBER_OF_PROCESSES = 10\n",
    "\n",
    "shutil.rmtree(\"staging-filtered\", ignore_errors=True)\n",
    "os.mkdir(\"staging-filtered\")\n",
    "chunks = np.array_split(nodes_filtered, NUMBER_OF_PROCESSES)\n",
    "\n",
    "filename = \"graph_filtered.pickle\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(graph_cyclic, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "filename = \"nodes_filtered.pickle\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(chunks, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "process_ids = set()\n",
    "process_name = \"communities_cycles.py\"\n",
    "for chunk_number in range(NUMBER_OF_PROCESSES):\n",
    "    process_id = str(uuid.uuid4())\n",
    "    process_ids = process_ids.union({process_id})\n",
    "    os.system(f\"{sys.executable} {process_name} {chunk_number} {process_id} &\")\n",
    "\n",
    "while get_processes(process_ids):\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89469745-f67c-4010-b08b-ef9a74aef25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for proc in get_processes(process_ids):\n",
    "    try:\n",
    "        proc.kill()\n",
    "    except psutil.NoSuchProcess:\n",
    "        pass\n",
    "\n",
    "communities_filtered = []\n",
    "for filename in glob(\"./staging-filtered/*.pickle\"):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        communities_filtered += pickle.load(f)\n",
    "\n",
    "filename = \"communities_filtered.pickle\"\n",
    "with open(filename, \"wb\") as f:\n",
    "    pickle.dump(communities_filtered, f)\n",
    "communities_filtered = [x[1] for x in communities_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1638111-4639-4d70-ac0a-282e4fc8812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities += communities_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f09166-dad7-4283-8ae3-ce4af82ca34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [len(x) for x in communities]\n",
    "round(np.mean(sizes)), round(np.median(sizes)), round(np.max(sizes)), sum(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f815c325-24e7-407a-8942-1dd7dd68fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d0355-1158-45c2-8eb5-f10ea8a22e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = pd.read_parquet(\"flows.parquet\")\n",
    "flow_stats = pd.read_parquet(\"flow_stats.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38836d7f-aba3-442b-b491-358d233d9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "search_hash = defaultdict(list)\n",
    "for index, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        search_hash[node].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535e4a4-5c66-47e4-be2b-2f58aed0e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "percentages = []\n",
    "start = time.time()\n",
    "for index, (group, grouped) in enumerate(flows.groupby(\"id\")):\n",
    "    flow_nodes = set(grouped[\"source\"]).union(grouped[\"target\"])\n",
    "    size = len(flow_nodes)\n",
    "    matches = []\n",
    "    perc = 0\n",
    "    for node in flow_nodes:\n",
    "        for i in search_hash[node]:\n",
    "            try:\n",
    "                matched_size = len(set(communities[i]).intersection(flow_nodes))\n",
    "            except KeyError:\n",
    "                continue\n",
    "            perc = matched_size / size\n",
    "            matches.append((node, perc))\n",
    "            if perc == 1:\n",
    "                break\n",
    "        if perc == 1:\n",
    "            break\n",
    "    matched_node_comm, perc = sorted(matches, reverse=True, key=lambda x: x[1])[0]\n",
    "    stats = flow_stats.loc[flow_stats[\"id\"] == group, :].iloc[0].to_dict()\n",
    "    stats[\"score\"] = perc\n",
    "    stats[\"matched_node_comm\"] = matched_node_comm\n",
    "    percentages.append(dict(stats))\n",
    "    if not (index % 2_000):\n",
    "        print(index, round(time.time() - start))\n",
    "        start = time.time()\n",
    "\n",
    "percentages = pd.DataFrame(percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7795a-41d0-48a8-9db8-e3bd7d48611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(percentages[\"score\"].mean(), 2) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c37321-cb7a-4a1b-8777-a70d02ca5549",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(percentages[percentages[\"score\"] == 1].shape[0] / percentages.shape[0], 2) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e6c149-b80c-4e1c-a832-ff24591b4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ = percentages[\"number_components\"] == 1\n",
    "percentages_scope = percentages.loc[filter_, :].reset_index(drop=True)\n",
    "percentages_scope.groupby(\"type\").agg({\"score\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826750d0-a830-4975-8fb5-ce1e20604f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages_scope[percentages_scope[\"score\"] < 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045ef9f-8169-4c43-998c-7febf60c5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages_scope[percentages_scope[\"score\"] < 1].groupby(\"sub_type\")[\"type\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d366e76-ffef-4a60-b49e-9757eb01af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = round(time.time() - start_script)\n",
    "print(f\"Script executed in {timedelta(seconds=delta)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b2d13-a460-4dc1-b3be-1524939a3834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
